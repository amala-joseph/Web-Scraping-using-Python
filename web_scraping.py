# -*- coding: utf-8 -*-
"""web_scraping.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1zKi_yhsfgartTK0aktwwHVnOu8SlXYIo
"""

#BeautifulSoup: BeautifulSoup is a Python library used for web scraping purposes to pull the data out of HTML and XML files. It creates a parse tree from page source code that can be used to extract data in a hierarchical and more readable manner.
from bs4 import BeautifulSoup
import requests
url="http://www.coursera.org"
r=requests.get(url)
soup=BeautifulSoup(r.content)
print(soup.prettify())

!pip install scrapy  # Install the scrapy module

#Scrapy: Scrapy is an open-source and collaborative web crawling framework for Python. It is used to extract the data from the website.
import scrapy
class QuotesSpider(scrapy.Spider):
  name="quotes"
  start_urls=['http:/quotes.toscrape.com/tag/humor/',]
def parse(self,response):
     for quote in response.css('div.quote'):
       yield {'quote':quote.css('span.text::text').get()}

!pip install selenium

#Selenium: Selenium is a tool used for controlling web browsers through programs and automating browser tasks.
from selenium import webdriver
driver=webdriver.Chrome()
driver.get("http://www.coursera.org")

#The Pandas library in Python contains a function read_html() that can be used to extract tabular information from any web page.
#Let us assume we want to extract the list of the largest banks in the world by market capitalization, from the following link:
import pandas as pd
url='https://en.wikipedia.org/wiki/List_of_largest_banks'
tables=pd.read_html(url)
df=tables[0]
df.columns=['Rank','Bank','Market Cap(US$ Billion)']
print(df)

#Although convenient, this method comes with its own set of limitations.
#Firstly, web pages may have content saved in them as tables but they may not appear as tables on the web page.
#For instance, consider the following URL showing the list of countries by GDP (nominal).
import pandas as pd
url='https://en.wikipedia.org/wiki/List_of_countries_by_GDP_(nominal)'
tables=pd.read_html(url)
df=tables[2]
print(df)

!pip install bs4
!pip install requests

from bs4 import BeautifulSoup
import requests
html="<!DOCTYPE html><html><head><title>Page Title</title></head><body><h3><b id='boldest'>Lebron James</b></h3><p> Salary: $ 92,000,000 </p><h3> Stephen Curry</h3><p> Salary: $85,000, 000 </p><h3> Kevin Durant </h3><p> Salary: $73,200, 000</p></body></html>"
#To parse a document, pass it into the BeautifulSoup constructor. The BeautifulSoup object represents the document as a nested data structure:
soup=BeautifulSoup(html,'html5lib')
#First, the document is converted to Unicode (similar to ASCII) and HTML entities are converted to Unicode characters. Beautiful Soup transforms a complex HTML document into a complex tree of Python objects. The BeautifulSoup object can create other types of objects. In this lab, we will cover BeautifulSoup and Tag objects, that for the purposes of this lab are identical. Finally, we will look at NavigableString objects.
#We can use the method prettify() to display the HTML in the nested structure:
print(soup.prettify())

#Let's say we want the title of the page and the name of the top paid player. We can use the Tag. The Tag object corresponds to an HTML tag in the original document, for example, the tag title.
tag_object=soup.title
print("Tag Object : ",tag_object)
print("Tag Object Type : ",type(tag_object))
#If there is more than one Tag with the same name, the first element with that Tag name is called. This corresponds to the most paid player:
tag_object=soup.h3
print("Tag Object : ",tag_object)
#As stated above, the Tag object is a tree of objects. We can access the child of the tag or navigate down the branch as follows:
tag_child=tag_object.b
print("Tag Child : ",tag_child)
#You can access the parent with the <code> parent</code>
parent_tag=tag_child.parent
print("Tag Parent : ",parent_tag)
sibling_1=tag_object.next_sibling
print("Siblings : ",sibling_1)
sibling_2=sibling_1.next_sibling
print("Siblings : ",sibling_2)
sibling_3=sibling_2.next_sibling
print("Siblings : ",sibling_3)
#If the tag has attributes, the tag id="boldest" has an attribute id whose value is boldest. You can access a tag’s attributes by treating the tag like a dictionary
print(tag_child['id'])
#You can access that dictionary directly as attrs:
print(tag_child.attrs)
#You can also work with Multi-valued attributes. Check out [1] for more.
#We can also obtain the content of the attribute of the tag using the Python get() method.
print(tag_child.get('id'))
#Navigable String
#A string corresponds to a bit of text or content within a tag. Beautiful Soup uses the NavigableString class to contain this text. In our HTML we can obtain the name of the first player by extracting the string of the Tag object tag_child as follows:
tag_string=tag_child.string
print(tag_string)
#we can verify the type is Navigable String
print(type(tag_string))
#A NavigableString is similar to a Python string or Unicode string. To be more precise, the main difference is that it also supports some BeautifulSoup features. We can convert it to string object in Python:
unicode_string = str(tag_string)
print(unicode_string)

#Filters allow you to find complex patterns, the simplest filter is a string. In this section we will pass a string to a different filter method and Beautiful Soup will perform a match against that exact string. Consider the following HTML of rocket launches:
table="<table><tr><td id='flight'>Flight No</td><td>Launch site</td> <td>Payload mass</td></tr><tr> <td>1</td><td><a href='https://en.wikipedia.org/wiki/Florida'>Florida<a></td><td>300 kg</td></tr><tr><td>2</td><td><a href='https://en.wikipedia.org/wiki/Texas'>Texas</a></td><td>94 kg</td></tr><tr><td>3</td><td><a href='https://en.wikipedia.org/wiki/Florida'>Florida<a> </td><td>80 kg</td></tr></table>"
table_bs = BeautifulSoup(table, 'html5lib')
#The find_all() method looks through a tag’s descendants and retrieves all descendants that match your filters.
#The Method signature for find_all(name, attrs, recursive, string, limit, **kwargs)
#When we set the name parameter to a tag name, the method will extract all the tags with that name and its children.
table_rows=table_bs.find_all('tr')
print(table_rows)
#The result is a Python Iterable just like a list, each element is a tag object:
first_row =table_rows[0]
print(first_row)
#The type is tag
print(type(first_row))
#we can obtain the child
print(first_row.td)
#If we iterate through the list, each element corresponds to a row in the table:
for i,row in enumerate(table_rows):
    print("row",i,"is",row)

#As row is a cell object, we can apply the method find_all to it and extract table cells in the object cells using the tag td, this is all the children with the name td. The result is a list, each element corresponds to a cell and is a Tag object, we can iterate through this list as well. We can extract the content using the string attribute.
for i,row in enumerate(table_rows):
    print("row",i)
    cells=row.find_all('td')
    for j,cell in enumerate(cells):
        print('colunm',j,"cell",cell)

#If we use a list we can match against any item in that list.
list_input=table_bs .find_all(name=["tr", "td"])
print(list_input)

#If the argument is not recognized it will be turned into a filter on the tag’s attributes. For example with the id argument, Beautiful Soup will filter against each tag’s id attribute. For example, the first td elements have a value of id of flight, therefore we can filter based on that id value.
table_bs.find_all(id="flight")
#We can find all the elements that have links to the Florida Wikipedia page:
list_input=table_bs.find_all(href="https://en.wikipedia.org/wiki/Florida")
print(list_input)
#If we set the href attribute to True, regardless of what the value is, the code finds all tags with href value:
table_bs.find_all(href=True)
#Using the logic above, find all the elements without <code>href</code> value
table_bs.find_all(href=False)
#Using the soup object soup, find the element with the id attribute content set to "boldest".
soup.find_all(id="boldest")
#With string you can search for strings instead of tags, where we find all the elments with Florida:
table_bs.find_all(string="Florida")

#The find_all() method scans the entire document looking for results. It’s useful if you are looking for one element, as you can use the find() method to find the first element in the document. Consider the following two tables:
two_tables="<h3>Rocket Launch </h3><p><table class='rocket'><tr><td>Flight No</td><td>Launch site</td> <td>Payload mass</td></tr><tr><td>1</td><td>Florida</td><td>300 kg</td></tr><tr><td>2</td><td>Texas</td><td>94 kg</td></tr><tr><td>3</td><td>Florida </td><td>80 kg</td></tr></table></p><p><h3>Pizza Party  </h3><table class='pizza'><tr><td>Pizza Place</td><td>Orders</td> <td>Slices </td></tr><tr><td>Domino's Pizza</td><td>10</td><td>100</td></tr><tr><td>Little Caesars</td><td>12</td><td >144 </td></tr><tr><td>Papa John's </td><td>15 </td><td>165</td></tr>"
#We create a BeautifulSoup object two_tables_bs
two_tables_bs= BeautifulSoup(two_tables, 'html.parser')
#We can find the first table using the tag name table
two_tables_bs.find("table",class_='pizza')

#Downloading And Scraping The Contents Of A Web Page
url = "http://www.ibm.com"
data  = requests.get(url).text
#We create a BeautifulSoup object using the BeautifulSoup constructor
soup=BeautifulSoup(data,"html5lib")
#Scrape all links
for link in soup.find_all('a',href=True):       # # in html anchor/link is represented by the tag <a>
    print(link.get('href'))

#Scrape all images Tags
for link in soup.find_all('img'):     # in html image is represented by the tag <img>
    print(link)
    print(link.get('src'))

#Scrape data from HTML tables
#The below url contains an html table with data about colors and color codes.
url = "https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/IBM-DA0321EN-SkillsNetwork/labs/datasets/HTMLColorCodes.html"
## get the contents of the webpage in text format and store in a variable called data
data  = requests.get(url).text
soup = BeautifulSoup(data,"html5lib")
#find a html table in the web page
table = soup.find('table') # in html table is represented by the tag <table>
#Get all rows from the table
for row in table.find_all('tr'): # in html table row is represented by the tag <tr>
    # Get all columns in each row.
    cols = row.find_all('td') # in html a column is represented by the tag <td>
    color_name = cols[2].string # store the value in column 3 as color_name
    color_code = cols[3].string # store the value in column 4 as color_code
    print("{}--->{}".format(color_name,color_code))

